---
title: "3 - Introduction to data management and cleaning"
author: | 
  | Hallie Eilerts-Spinelli
  | \texttt{\href{mailto:heilert1@jh.edu}{heilert1@jh.edu}}
  | Johns Hopkins Bloomberg School of Public Health
  | Applied Data Analysis
date: "March 2025"
output: 
   beamer_presentation:
    keep_tex: true
    latex_engine: xelatex
    highlight: espresso
    toc: false
header-includes:
  - \input{myheader.tex}
colorlinks: true
urlcolor: JHBlue
linkcolor: HeritageBlue
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
options(tinytex.verbose = TRUE)
library(knitr)
library(kableExtra)
library(tidyr)
```

# Introduction

## Motivation (I)

Things (data, code, resources, drafts, etc.) can become disorganized as any research project progresses.

```{r, echo = FALSE}
include_graphics("figures/messy-files.jpg")
```

If you're not careful, this disorganization may seep into your analysis, compromising your results.

## Motivation (II)

**Following a structured approach to setting up your project is one of the best things you can do to ensure validity, efficiency, clarity, and reproducibility.**


## Agenda

1.  Directory structure and file organization
2.  Naming and notation
3.  Coding style
4.  Workflow


# Directory structure and file organization

## Directory structure (I)

\scriptsize

Before you start working with data, you should decide how you will structure and name files and folders. Ensuring that data, code, and results are systematically arranged makes it easier to conduct analysis, debug, and collaborate.

\textcolor{JHOrange}{Basic project structure organized by file type.}

\tiny

```
project
 |
 |-- data
 |  |  
 |  +-- SurveyRaw2024.xlsx
 |  +-- README.txt 
 |    
 |-- code
 |  |  
 |  +-- data-prep.R
 |  +-- data-analysis.R 
 |    
 |-- results
 |  |  
 |  +-- figure1.jpeg
 |  +-- figure2.jpeg
 |  +-- table1.doc
 |    
```

## Directory structure (II)

\scriptsize

\textcolor{JHOrange}{More elaborated structure. Subfolders for data and code and folders for documentation and different types of outputs.}

\tiny

```
project
 |
 |-- data
 |  |  
 |  |-- raw-data
 |  |-- processed-data
 |    
 |-- code
 |  |  
 |  |-- cleaning
 |  |-- analysis 
 |    
 |-- documentation
 |  |  
 |  |-- ethics
 |  |   +-- ethics-approval.pdf 
 |  |   +-- consent-form.docx
 |  |-- methods
 |  |   +-- methods_decription.docx 
 |  |   +-- README.txt
 |    
 |-- outputs
 |  |  
 |  |-- figures
 |  |-- tables
 |  |-- paa-conference-2025
 |  |   +-- manuscript01_20241002.docx
 |  |   +-- references.bib
 |    
```

## Directory structure (III)

\scriptsize

\textcolor{JHOrange}{Pipeline style, separating source code from generated outputs.}

\tiny

```
project
 |  
 +-- make.R
 |-- data
 |-- src
 |  |-- data-preparation
 |      +-- prepare_session.R
 |      +-- clean_data.R
 |  |-- analysis
 |      +-- calc_summary_stats.R
 |      +-- fit_model.R
 |  |-- figures
 |      +-- visualizations.R
 |-- gen
 |  |  
 |  |-- data-preparation
 |      |-- output
 |          +-- survey-clean-20240206.csv
 |      |-- temp
 |          +-- duplicates.csv
 |  |-- analysis
 |      |-- audit
 |          +-- correlation-plots.pdf
 |      |-- output
 |          +-- model-fit.RData
 |  |-- figures
 |      |-- output
 |          +-- coverage-trend_2000-2020.pdf
```

## Folder hierarchy

-   Does it work better for your project to have a \textcolor{JHOrange}{flat} structure with many files in a few folders?
    -   Or a \textcolor{JHOrange}{nested} structure with multiple subfolders and a few files in each?
-   Avoid too many files in each folder (\>10 or 15)
-   Avoid excessive levels of folders (\>3 or 4)
-   Document your project/folder structure in a `README` file

## Data

-   Back up raw data securely
-   If you have multiple datasets, create a separate subfolder for each
-   Include codebook or `README` describing data. Include...
    -   From whom/where
    -   When it was received/procured
    
## Code and outputs

-   Keep scripts separate from outputs they generate
-   Do not store copies of the same file in different folders

## Naming folders and files

-   Use standard ASCII alphanumeric characters
-   Avoid spaces, dots
-   Clear but short names
-   Useful elements in a filename
    -   Indication of the content (abbreviated or encoded)
    -   Date (in the format \textcolor{JHOrange}{YYYYMMDD})
    -   Version number
-   Use hyphens or dashes to separate different elements in your filename
-   **Do not** use ambiguous descriptions of the version, such as `_new`, `_lastversion` or `_revised`

\tiny

\makebox[\textwidth]{(\href{https://libguides.uvt.nl/rdmstudent/filenames}{Tilburg University})}

# Coding style


## Coding style

\small

If your code is messy, it's hard to be confident in your results. Messy code also be difficult to understand, debug, and tweak (especially when you come back to it a few weeks/months later!).

\vspace{1em}

**Using a consistent coding style throughout your project is important for clarity and quality control.**

\vspace{1em}

Find a style guide and stick to it. Examples:

-   [Advanced-R Styleguide](http://adv-r.had.co.nz/Style.html)
-   [Google's R Styleguide](https://google.github.io/styleguide/Rguide.html)

## Notation and naming (I)

\footnotesize

Adopt a case style to improve readability and be consistent in usage. Some options:

1.  Variable names as descriptive nouns in `camelCase` or `snake_case`

```{r, eval = FALSE}
# camel
outcomesTable
summaryStats
# snake
model_output
data_long
```

2.  Functions as descriptive verbs in `PascalCase`

```{r, eval = FALSE}
MakeBoxPlot()
FetchValue()
```

Note: R allows "." in variable names and functions but this goes against best practices in other coding languages.

## Notation and naming (II)

\footnotesize

3.  Save outputs in `kebab-case`

    -   \footnotesize Use a suffix can to indicate alterations of parent object (*survey-sample_females.csv*).

4.  Usage of variable type as a prefix. Can improve clarity, but also more verbose.

```{r, eval = FALSE}
df_results   # data frame of results
l_results    # list of results

df_countries # data frame with country info
v_countries  # vector of country names

dat          # original data
datLong      # data reshaped long
datWide      # data rehaped wide

fn_makeBoxPlot() # custom function for making boxplot
```

## Syntax

-   Use two spaces per level of indentation
-   Put spaces around operators (e.g., +, -, \*), after commas
-   An opening curly brace is never on it's own line, but a closing curly brace always is
-   Use `<-` when assigning values to variables in R
    -   Reserve `=` for argument passing in functions
    -   Note the important difference between `=` and `==` in R
-   Useful [RStudio addin](https://www.r-bloggers.com/2016/10/align-assign-rstudio-addin-to-align-assignment-operators/) that helps align code neatly

## Organization

\footnotesize

-   Load packages at the top of script
-   Comment your code!
-   Organize code into blocks to accomplish a single goal, describe that goal in comment
-   Use in-line comments sparingly
-   Adopt a file header that is included in every script and allows it to be interpreted on its own

\vspace{1em}

\tiny

```{r, eval = FALSE}
################################################################################
# @project Example Project
# @description This file is responsible for cleaning column names
# @return Data frame with cleaned column names
################################################################################
```

\centering

[kmishra9 best practices](https://github.com/kmishra9/Best-Practices-for-Writing-R-Code)

# Workflow

## Data preparation theory

building a data analysis pipeline

![](figures/data-prep-theory.png){width="350px"}

\tiny

<https://dprep.hannesdatta.com/docs/modules/week2/>

## Steps in data preparation

Data preparation theory: components of source code

```         
1) Initializing the script/setup. Setup such as loading packages, setting variables, making database connection
    Loading packages, Making connections to databases, Any other “main” parameters (e.g., “Knowing” whether to prototype or not)
2) Input (e.g., loading data)
  Read data (e.g., unstructured/unstructured data, remote/local locations, files or databases)
3) Transformation
    e.g., filtering, aggregation, merging, transformation, deduplication (more later) 
    many options…: filtering, grouping and summarizing, creating new variables, etc.
    mostly leads to a “different primary key than the input data” (–> unit of analysis!)
4) Output (e.g., saving, passing on to the next script)
   Store (intermediate) data, figures (e.g., auditing, final)
```

Each and every source code file obeys to the “setup-ITO” (input, transformation, output) procedure.

<https://dprep.hannesdatta.com/docs/modules/week2/tutorial/tutorial#/4>

## Flow

Data should flow through a script

load data analyze save output

## Modularization

Split code into chunks. Everything with an input and output.

![](figures/modularization.png){width="350px"}

\tiny

<https://dprep.hannesdatta.com/docs/modules/week5/>

## Make file

Include a \textcolor{JHAccentRed}{\tt make} file sourcing scripts in the order necessary to execute the analysis

## Guidelines

-   Include a `makefile` with scripts run in order necessary to execute analysis
    -   Alternatively, include a `readme` with project description and instructions for how to run/build the project
-   Ensure file names are relative and not absolute



# Hal to-do's

## Still need to look at

Full tutorial of data prep: <https://dprep.hannesdatta.com/docs/modules/week2/tutorial/intro-to-r> Full tutorial for engineering datasets: <https://dprep.hannesdatta.com/docs/modules/week4/tutorial/data-preparation>

## Resources

[R for Social Scientists](https://datacarpentry.github.io/r-socialsci/)

Data carpentry github: <https://github.com/datacarpentry/r-socialsci/blob/main/episodes/00-intro.Rmd>

[Introduction to R](https://www.datacamp.com/courses/free-introduction-to-r)

[Introduction to Github](https://github.com/skills/introduction-to-github)

## References

[RStudio User Guide](https://docs.posit.co/ide/user/)

[R for Social Scientistics](https://datacarpentry.github.io/r-socialsci/index.html)

[Tilburg Science Hub](https://tilburgsciencehub.com/)

[ClaytonJY R style guide](https://github.com/ClaytonJY/R-Styleguide?tab=readme-ov-file)

[Roman Pahl R bloggers style guide](https://www.r-bloggers.com/2019/11/my-r-style-guide/)

[Tilburg Science Hub](https://tilburgsciencehub.com/topics/automation/workflows/auditing/workflow-checklist/)
